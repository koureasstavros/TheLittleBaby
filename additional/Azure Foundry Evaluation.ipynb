{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Azure Foundry Setup ===\n",
    "API_URL = os.getenv(\"AZEV_API_URL\")\n",
    "API_KEY = os.getenv(\"AZEV_API_KEY\")\n",
    "MODEL_ID = os.getenv(\"AZEV_MODEL_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd90f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96973c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process Each File ===\n",
    "def process_files(folder_path, file_prefix):\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.startswith(file_prefix):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    completion_old = json.load(f)\n",
    "                    generation_old = completion_old.get(\"generation\", \"No prompt provided.\")\n",
    "\n",
    "                payload = {\n",
    "                    \"model\": MODEL_ID,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are an intelligent assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\":\n",
    "                            f\"Evaluate the following generated text by checking the Coherence, Consistency, Grammar, Syntax, Spelling\" +\n",
    "                            f\"Try to be as concise as possible, so everytime the score will be the same.\" +\n",
    "                            f\"Always provide the total-score at the top and sub-score inline with explanation.\" +\n",
    "                            f\"The score should be an integer number between 1 and 100, where 1 is the worst and 100 is the best.\" +\n",
    "                            f\"Output only the integer score number\" +\n",
    "                            f\"\\n\\n\"\n",
    "                            f\"\\\"{generation_old}\\\"\"\n",
    "                         }\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                for i in range(epochs):\n",
    "                    score_new = 0\n",
    "                    score_cnt = 0\n",
    "                    generation_new = \"\"\n",
    "                    response = requests.post(url=API_URL, headers=HEADERS, json=payload)\n",
    "                    response_json = response.json()\n",
    "                    try:\n",
    "                        generation_new = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "                        score_cnt += 1\n",
    "                        score_new += int(generation_new.split()[0])\n",
    "                        if debug:\n",
    "                            print(f\"\\nðŸ“„ {filename}\\nModel Output:\\n{generation_new}\")\n",
    "                    except (KeyError, IndexError, ValueError):\n",
    "                        if debug:\n",
    "                            print(f\"\\nðŸ“„ {filename}\\nModel Output:\\n{response_json}\")\n",
    "\n",
    "                score_avg = score_new // score_cnt if score_cnt > 0 else 0\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    \n",
    "                    print(f\"\\nðŸ“„ {filename}\\nEvaluation:\\n{score_avg}\")\n",
    "                    completion_old[\"evaluation\"] = score_avg\n",
    "                    completion_old = json.dump(completion_old, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6abe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run the script ===\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"../outputs\"\n",
    "    file_prefix = \"completion_\"\n",
    "    process_files(folder_path, file_prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3-12-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

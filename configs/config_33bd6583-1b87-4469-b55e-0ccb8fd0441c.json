{
    "n_ctx": 8,
    "n_emb": 128,
    "dropout": 0.1,
    "head_size": 128,
    "n_heads": 16,
    "n_layers": 16,
    "num_epochs": 1,
    "batch_size": 16,
    "lr": 0.001
}